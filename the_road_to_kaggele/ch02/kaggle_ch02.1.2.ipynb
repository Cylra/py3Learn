{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.datasets导入波士顿房价数据读取器。\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 读取房价数据\n",
    "boston = load_boston()\n",
    "# 输出数据描述。\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据分割器。\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max target value is 50.0\n",
      "The min target value is 5.0\n",
      "The average target value is 22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# 随机采样25%的数据构建测试样本，其余作为训练样本。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33, test_size=0.25)\n",
    "\n",
    "# 分析回归目标值的差异。\n",
    "print(\"The max target value is\", np.max(boston.target))\n",
    "print(\"The min target value is\", np.min(boston.target))\n",
    "print(\"The average target value is\", np.mean(boston.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据标准化模块。\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 分别初始化对特征和目标值的标准化器。\n",
    "ss_X = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据的特征以及目标值进行标准化处理。\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "X_test = ss_X.transform(X_test)\n",
    "\n",
    "y_train = ss_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = ss_y.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入LinearRegression。\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "# 对测试数据进行回归预测。\n",
    "lr_y_predict = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入SGDRegressor。\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgdr = SGDRegressor()\n",
    "sgdr.fit(X_train, y_train.ravel())\n",
    "# 对测试数据进行回归预测。\n",
    "sgdr_y_predict = sgdr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of default measurement of LinearRegression is -5.826896537214896\n"
     ]
    }
   ],
   "source": [
    "# 使用LinearRegression模型自带的评估模块，并输出评估结果。\n",
    "print('The value of default measurement of LinearRegression is', lr.score(X_test, y_test))\n",
    "\n",
    "# 导入r2_score、mean_squared_error以及mean_absoluate_error用于回归性能的评估。\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of R-squared of LinearRegression is -5.826896537214896\n",
      "The mean squared error of LinearRegression is 529.3663953404998\n",
      "The mean absoluate error of LinearRegression is 21.537789484481902\n"
     ]
    }
   ],
   "source": [
    "# 使用r2_score、mean_squared_error、mean_absolute_error模块，并输出评估结果。\n",
    "print('The value of R-squared of LinearRegression is',\n",
    "      r2_score(y_test, lr_y_predict))\n",
    "\n",
    "print('The mean squared error of LinearRegression is',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(lr_y_predict))\n",
    "     )\n",
    "\n",
    "print('The mean absoluate error of LinearRegression is',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(lr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of default measurement of SGDRegressor is -5.821742931395504\n",
      "The value of R-squared of SGDRegressor is -5.821742931395504\n",
      "The mean squared error of SGDRegressor is 528.966778073599\n",
      "The mean absoluate error of SGDRegressor is 21.525759320203047\n"
     ]
    }
   ],
   "source": [
    "# 使用SGDRegressor模型自带的评估模块，并输出评估结果。\n",
    "print('The value of default measurement of SGDRegressor is', \n",
    "      sgdr.score(X_test, y_test))\n",
    "\n",
    "print('The value of R-squared of SGDRegressor is', \n",
    "      r2_score(y_test, sgdr_y_predict))\n",
    "\n",
    "print('The mean squared error of SGDRegressor is', \n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(sgdr_y_predict))\n",
    "     )\n",
    "\n",
    "print('The mean absoluate error of SGDRegressor is', \n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(sgdr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.svm中导入支持向量机（回归）模型。\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# 使用线性核函数配置的支持向量机进行回归训练，并且对测试样本进行预测。\n",
    "linear_svr = SVR(kernel='linear')\n",
    "linear_svr.fit(X_train, y_train.ravel())\n",
    "linear_svr_y_predict = linear_svr.predict(X_test)\n",
    "\n",
    "# 使用多项式核函数配置的支持向量机进行回归训练，并且对测试样本进行预测。\n",
    "poly_svr = SVR(kernel='poly')\n",
    "poly_svr.fit(X_train, y_train.ravel())\n",
    "poly_svr_y_predict = poly_svr.predict(X_test)\n",
    "\n",
    "# 使用径向基核函数配置的支持向量机进行回归训练，并且对测试样本进行预测。\n",
    "rbf_svr = SVR(kernel='rbf')\n",
    "rbf_svr.fit(X_train, y_train.ravel())\n",
    "rbf_svr_y_predict = rbf_svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of linear SVR is -5.887962223053588\n",
      "The mean squared error of linear SVR is 534.1015076737845\n",
      "The mean absoluate error of linear SVR is 21.644361940770704\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE和MAE指标对三种配置的支持向量机（回归）模型在相同测试集上进行性能评估。\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "print('R-squared value of linear SVR is',\n",
    "      linear_svr.score(X_test, y_test))\n",
    "\n",
    "print('The mean squared error of linear SVR is',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(linear_svr_y_predict))\n",
    "     )\n",
    "print('The mean absoluate error of linear SVR is',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(linear_svr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of Poly SVR is -5.830457473877632\n",
      "The mean squared error of Poly SVR is 529.6425149791839\n",
      "The mean absoluate error of Poly SVR is 21.575153797852472\n"
     ]
    }
   ],
   "source": [
    "print('R-squared value of Poly SVR is',\n",
    "      poly_svr.score(X_test, y_test))\n",
    "\n",
    "print('The mean squared error of Poly SVR is',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(poly_svr_y_predict))\n",
    "     )\n",
    "\n",
    "print('The mean absoluate error of Poly SVR is',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(poly_svr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of RBF SVR is -5.861497287191408\n",
      "The mean squared error of RBF SVR is 532.0493822865151\n",
      "The mean absoluate error of RBF SVR is 21.582537351208934\n"
     ]
    }
   ],
   "source": [
    "print('R-squared value of RBF SVR is',\n",
    "      rbf_svr.score(X_test, y_test))\n",
    "\n",
    "print('The mean squared error of RBF SVR is',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rbf_svr_y_predict))\n",
    "     )\n",
    "\n",
    "print('The mean absoluate error of RBF SVR is',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rbf_svr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入KNeighborRegressor（K近邻回归器）。\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# 初始化K近邻回归器，并且调整配置，使得预测的方式为平均回归：weights='uniform'。\n",
    "uni_knr = KNeighborsRegressor(weights='uniform')\n",
    "uni_knr.fit(X_train, y_train)\n",
    "uni_knr_y_predict = uni_knr.predict(X_test)\n",
    "\n",
    "# 初始化K近邻回归器，并且调整配置，使得预测的方式为根据距离加权回归：weights='distance'。\n",
    "dis_knr = KNeighborsRegressor(weights='distance')\n",
    "dis_knr.fit(X_train, y_train)\n",
    "dis_knr_y_predict = dis_knr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of uniform-weighted KNeighorRegression: -5.898574928779067\n",
      "The mean squared error of uniform-weighted KNeighorRegression: 534.9244306145499\n",
      "The mean absoluate error of uniform-weighted KNeighorRegression 21.6287851971816\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE三种指标对平均回归配置的K近邻模型在测试集上进行性能评估。\n",
    "print('R-squared value of uniform-weighted KNeighorRegression:',\n",
    "      uni_knr.score(X_test, y_test))\n",
    "\n",
    "print('The mean squared error of uniform-weighted KNeighorRegression:',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(uni_knr_y_predict))\n",
    "     )\n",
    "\n",
    "print('The mean absoluate error of uniform-weighted KNeighorRegression',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(uni_knr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of distance-weighted KNeighorRegression: -5.883085438592986\n",
      "The mean squared error of distance-weighted KNeighorRegression: 533.7233554934066\n",
      "The mean absoluate error of distance-weighted KNeighorRegression: 21.613676200534318\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE三种指标对根据距离加权回归配置的K近邻模型在测试集上进行性能评估。\n",
    "print('R-squared value of distance-weighted KNeighorRegression:',\n",
    "      dis_knr.score(X_test, y_test))\n",
    "\n",
    "print('The mean squared error of distance-weighted KNeighorRegression:',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dis_knr_y_predict))\n",
    "     )\n",
    "print('The mean absoluate error of distance-weighted KNeighorRegression:',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dis_knr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of distance-weighted KNeighorRegression: -5.883085438592986\n",
      "The mean squared error of distance-weighted KNeighorRegression: 533.7233554934066\n",
      "The mean absoluate error of distance-weighted KNeighorRegression: 21.613676200534318\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE三种指标对根据距离加权回归配置的K近邻模型在测试集上进行性能评估。\n",
    "print('R-squared value of distance-weighted KNeighorRegression:',\n",
    "      dis_knr.score(X_test, y_test))\n",
    "\n",
    "print('The mean squared error of distance-weighted KNeighorRegression:',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dis_knr_y_predict))\n",
    "     )\n",
    "print('The mean absoluate error of distance-weighted KNeighorRegression:',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dis_knr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入DecisionTreeRegressor。\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "# 用波士顿房价的训练数据构建回归树。\n",
    "dtr.fit(X_train, y_train)\n",
    "# 使用默认配置的单一回归树对测试数据进行预测\n",
    "dtr_y_predict = dtr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of DecisionTreeRegressor: -5.77194942743176\n",
      "The mean squared error of DecisionTreeRegressor: 525.1057253154429\n",
      "The mean absoluate error of DecisionTreeRegressor: 21.487237181064327\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE指标对默认配置的回归树在测试集上进行性能评估。\n",
    "print('R-squared value of DecisionTreeRegressor:',\n",
    "      dtr.score(X_test, y_test))\n",
    "\n",
    "print('The mean squared error of DecisionTreeRegressor:',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dtr_y_predict))\n",
    "     )\n",
    "\n",
    "print('The mean absoluate error of DecisionTreeRegressor:',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dtr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入RandomForestRegressor、ExtraTreesGressor以及GradientBoostingRegressor。\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "\n",
    "# 使用RandomForestRegressor训练模型，并对测试数据做出预测\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train.ravel())\n",
    "rfr_y_predict = rfr.predict(X_test)\n",
    "\n",
    "# 使用ExtraTreesRegressor训练模型，并对测试数据做出预测\n",
    "etr = ExtraTreesRegressor()\n",
    "etr.fit(X_train, y_train.ravel())\n",
    "etr_y_predict = etr.predict(X_test)\n",
    "\n",
    "# 使用GradientBoostingRegressor训练模型，并对测试数据做出预测\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train.ravel())\n",
    "gbr_y_predict = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of RandomForestRegressor: -5.7908852966890025\n",
      "The mean squared error of RandomForestRegressor: 526.5740371313174\n",
      "The mean absoluate error of RandomForestRegressor: 21.511180364848027\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE指标对默认配置的随机回归森林在测试集上进行性能评估。\n",
    "print('R-squared value of RandomForestRegressor:',\n",
    "      rfr.score(X_test, y_test))\n",
    "\n",
    "print('The mean squared error of RandomForestRegressor:',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rfr_y_predict))\n",
    "     )\n",
    "\n",
    "print('The mean absoluate error of RandomForestRegressor:',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rfr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of ExtraTreesRegessor: -5.816303779330491\n",
      "The mean squared error of  ExtraTreesRegessor: 528.5450191811551\n",
      "The mean absoluate error of ExtraTreesRegessor: 21.544871202445155\n",
      "[['0.003874289354477088' 'AGE']\n",
      " ['0.014441301851180232' 'B']\n",
      " ['0.018696144984278157' 'CHAS']\n",
      " ['0.01905108020946717' 'CRIM']\n",
      " ['0.020306887755394583' 'DIS']\n",
      " ['0.024333857607445823' 'INDUS']\n",
      " ['0.02474345673493861' 'LSTAT']\n",
      " ['0.03677411448526542' 'NOX']\n",
      " ['0.037711407225922845' 'PTRATIO']\n",
      " ['0.0384296080688791' 'RAD']\n",
      " ['0.06273786959755033' 'RM']\n",
      " ['0.34394843935553565' 'TAX']\n",
      " ['0.35495154276966495' 'ZN']]\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE指标对默认配置的极端回归森林在测试集上进行性能评估。\n",
    "print('R-squared value of ExtraTreesRegessor:',\n",
    "      etr.score(X_test, y_test))\n",
    "\n",
    "print('The mean squared error of  ExtraTreesRegessor:',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(etr_y_predict))\n",
    "     )\n",
    "\n",
    "print('The mean absoluate error of ExtraTreesRegessor:',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(etr_y_predict))\n",
    "     )\n",
    "\n",
    "# 利用训练好的极端回归森林模型，输出每种特征对预测目标的贡献度。\n",
    "print(np.sort( list(zip(etr.feature_importances_, boston.feature_names)), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of GradientBoostingRegressor: -5.793084100380008\n",
      "The mean squared error of GradientBoostingRegressor: 526.744535216007\n",
      "The mean absoluate error of GradientBoostingRegressor: 21.515870420485697\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE指标对默认配置的梯度提升回归树在测试集上进行性能评估。\n",
    "print('R-squared value of GradientBoostingRegressor:',\n",
    "      gbr.score(X_test, y_test))\n",
    "\n",
    "print('The mean squared error of GradientBoostingRegressor:',\n",
    "      mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(gbr_y_predict))\n",
    "     )\n",
    "\n",
    "print('The mean absoluate error of GradientBoostingRegressor:',\n",
    "      mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(gbr_y_predict))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
